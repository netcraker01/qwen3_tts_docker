# Qwen3-TTS Service API

[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688.svg?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

> Servicio Docker de Texto a Voz (TTS) basado en **Qwen3-TTS** de Alibaba Cloud con API REST.

**Repositorio**: https://github.com/netcraker01/qwen3_tts_docker

Servicio Docker de Texto a Voz (TTS) basado en **Qwen3-TTS** con soporte para:
- ðŸŽ­ **Custom Voice**: Voces preestablecidas (Vivian, Ryan, Sohee, etc.)
- ðŸŽ¨ **Voice Design**: Crear voces por descripciÃ³n de texto
- ðŸŽ¤ **Voice Clone**: ClonaciÃ³n Zero-Shot desde audio de referencia

## ðŸš€ CaracterÃ­sticas

- **Modelo 1.7B**: Alta calidad de sÃ­ntesis de voz
- **API REST**: FastAPI con documentaciÃ³n OpenAPI/Swagger automÃ¡tica
- **Soporte GPU**: Optimizado para CUDA con Flash Attention
- **Multi-idioma**: EspaÃ±ol, InglÃ©s, Chino, JaponÃ©s, Coreano, AlemÃ¡n, FrancÃ©s, Ruso, PortuguÃ©s, Italiano
- **Lazy Loading**: Carga modelos bajo demanda para optimizar memoria

## ðŸ“‹ Requisitos

- Docker y Docker Compose
- NVIDIA Docker Runtime (para soporte GPU)
- GPU con al menos 8GB VRAM (recomendado 12GB)
- ~10GB espacio en disco para modelos

## ðŸ› ï¸ InstalaciÃ³n y Uso

### Prerrequisitos

Antes de comenzar, asegÃºrate de tener instalado:

1. **Docker Desktop** (Windows/Mac) o **Docker Engine** (Linux)
   - [Descargar Docker Desktop](https://www.docker.com/products/docker-desktop)

2. **NVIDIA Docker Runtime** (solo para GPU)
   ```bash
   # Linux - Ubuntu/Debian
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
   curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
   sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
   sudo systemctl restart docker
   
   # Verificar instalaciÃ³n
   docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
   ```

3. **Git**
   - [Descargar Git](https://git-scm.com/downloads)

---

### Paso 1: Clonar el Repositorio

```bash
# Clonar desde GitHub
git clone https://github.com/netcraker01/qwen3_tts_docker.git

# Entrar al directorio
cd qwen3_tts_docker

# Verificar archivos
ls -la
```

---

### Paso 2: Preparar el Entorno

```bash
# Crear directorios necesarios (si no existen)
mkdir -p models output

# Verificar estructura
tree -L 2
# o
ls -R
```

**Estructura esperada:**
```
qwen3_tts_docker/
â”œâ”€â”€ app/              # CÃ³digo fuente
â”œâ”€â”€ models/           # Cache de modelos (se crearÃ¡ automÃ¡ticamente)
â”œâ”€â”€ output/           # Archivos generados (se crearÃ¡ automÃ¡ticamente)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

### Paso 3: Configurar Variables de Entorno (Opcional)

Crea un archivo `.env` para personalizar la configuraciÃ³n:

```bash
# Crear archivo .env
cat > .env << EOF
# GPU Configuration
CUDA_VISIBLE_DEVICES=0

# Model Configuration
DEFAULT_MODEL_SIZE=1.7B
USE_FLASH_ATTENTION=true
MODEL_CACHE_DIR=/app/models

# Service Configuration
LOG_LEVEL=info
EOF
```

**Variables disponibles:**

| Variable | DescripciÃ³n | Valor por defecto |
|----------|-------------|-------------------|
| `CUDA_VISIBLE_DEVICES` | ID de la GPU a usar | `0` |
| `DEFAULT_MODEL_SIZE` | TamaÃ±o del modelo (`1.7B` o `0.6B`) | `1.7B` |
| `USE_FLASH_ATTENTION` | Activar Flash Attention (mÃ¡s rÃ¡pido) | `true` |
| `LOG_LEVEL` | Nivel de logs (`debug`, `info`, `warning`, `error`) | `info` |

---

### Paso 4: Construir la Imagen Docker

```bash
# Construir la imagen (primera vez ~5-10 minutos)
docker-compose build

# O construir sin cachÃ© (si hay problemas)
docker-compose build --no-cache
```

**Nota:** La construcciÃ³n descarga:
- Imagen base CUDA 12.1 (~2GB)
- Dependencias Python
- Flash Attention (compilaciÃ³n desde cÃ³digo fuente)

---

### Paso 5: Iniciar el Servicio

```bash
# Iniciar en modo detached (background)
docker-compose up -d

# Verificar que estÃ¡ corriendo
docker-compose ps

# Ver logs en tiempo real
docker-compose logs -f qwen3-tts

# Ver logs recientes (Ãºltimas 100 lÃ­neas)
docker-compose logs --tail=100 qwen3-tts
```

**Primera ejecuciÃ³n:** Se descargarÃ¡n automÃ¡ticamente los modelos de HuggingFace (~4-6GB). Esto puede tardar 10-30 minutos dependiendo de tu conexiÃ³n.

---

### Paso 6: Verificar la InstalaciÃ³n

```bash
# Test de health check
curl http://localhost:8000/api/v1/health

# Ver informaciÃ³n de modelos
curl http://localhost:8000/api/v1/models

# Listar speakers disponibles
curl http://localhost:8000/api/v1/speakers
```

**Respuesta esperada del health check:**
```json
{
  "status": "healthy",
  "models_loaded": [],
  "cuda_available": true,
  "gpu_count": 1,
  "gpu_name": "NVIDIA GeForce RTX 3060"
}
```

---

### Paso 7: Acceder a la DocumentaciÃ³n

- **API Docs (Swagger UI)**: http://localhost:8000/docs
- **API Docs (ReDoc)**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/api/v1/health

## ðŸ“¡ Endpoints API

### Health & Info

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/api/v1/health` | GET | Estado del servicio |
| `/api/v1/models` | GET | InformaciÃ³n de modelos |
| `/api/v1/speakers` | GET | Listar speakers disponibles |
| `/api/v1/languages` | GET | Listar idiomas soportados |

### Text-to-Speech

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/api/v1/tts/custom` | POST | Voz con personaje preestablecido |
| `/api/v1/tts/design` | POST | Voz por descripciÃ³n de texto |
| `/api/v1/tts/clone/url` | POST | Clonar desde URL de audio |
| `/api/v1/tts/clone/upload` | POST | Clonar subiendo archivo |
| `/api/v1/tts/custom/file` | POST | Generar y descargar archivo |

## ðŸ’¡ Ejemplos de Uso

### Custom Voice

```bash
curl -X POST "http://localhost:8000/api/v1/tts/custom" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Â¡Hola! Esta es una prueba de sÃ­ntesis de voz.",
    "speaker": "Sohee",
    "language": "Spanish",
    "instruction": "Feliz y enÃ©rgica",
    "output_format": "wav"
  }'
```

### Voice Design

```bash
curl -X POST "http://localhost:8000/api/v1/tts/design" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Bienvenidos a la presentaciÃ³n de hoy.",
    "voice_description": "gender: Female, pitch: Medium, speed: Moderate, emotion: Professional",
    "language": "Spanish",
    "output_format": "wav"
  }'
```

### Voice Clone (URL)

```bash
curl -X POST "http://localhost:8000/api/v1/tts/clone/url" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Esta es mi voz clonada hablando.",
    "ref_audio_url": "https://ejemplo.com/mi-voz.wav",
    "ref_text": "Hola, esta es mi voz de referencia.",
    "language": "Spanish"
  }'
```

### Voice Clone (Upload)

```bash
curl -X POST "http://localhost:8000/api/v1/tts/clone/upload" \
  -F "text=Esta es mi voz clonada" \
  -F "ref_text=Hola, esta es mi voz" \
  -F "language=Spanish" \
  -F "ref_audio=@/ruta/a/mi-voz.wav"
```

## ðŸŽ­ Speakers Disponibles

| Speaker | GÃ©nero | Idioma | Estilo |
|---------|--------|--------|--------|
| Vivian | Female | Chinese | Natural |
| Serena | Female | English | Professional |
| Uncle_Fu | Male | Chinese | Mature |
| Dylan | Male | English | Young |
| Eric | Male | English | Professional |
| Ryan | Male | English | Conversational |
| Aiden | Male | English | Versatile |
| Ono_Anna | Female | Japanese | Anime |
| Sohee | Female | Korean | Natural |

## ðŸŒ Idiomas Soportados

- Auto (detecciÃ³n automÃ¡tica)
- Spanish
- English
- Chinese
- Japanese
- Korean
- German
- French
- Russian
- Portuguese
- Italian

## âš™ï¸ ConfiguraciÃ³n

Variables de entorno en `docker-compose.yml`:

| Variable | DescripciÃ³n | Default |
|----------|-------------|---------|
| `CUDA_VISIBLE_DEVICES` | GPU a usar | 0 |
| `MODEL_CACHE_DIR` | Directorio cachÃ© de modelos | /app/models |
| `DEFAULT_MODEL_SIZE` | TamaÃ±o modelo (1.7B o 0.6B) | 1.7B |
| `USE_FLASH_ATTENTION` | Usar Flash Attention | true |
| `LOG_LEVEL` | Nivel de logs | info |

## ðŸ“ Estructura del Proyecto

```
qwen3-tts-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py          # Endpoints REST
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ requests.py        # Modelos Pydantic
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ tts_service.py     # LÃ³gica TTS
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                # Entry point FastAPI
â”œâ”€â”€ models/                    # CachÃ© de modelos (volumen)
â”œâ”€â”€ output/                    # Archivos generados (volumen)
â”œâ”€â”€ Dockerfile                 # Imagen Docker
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n
â”œâ”€â”€ requirements.txt           # Dependencias
â””â”€â”€ README.md                  # Este archivo
```

## ðŸ”§ Desarrollo

### Sin Docker (desarrollo local)

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar
python -m uvicorn app.main:app --reload --port 8000
```

### Testing

```bash
# Health check
curl http://localhost:8000/api/v1/health

# Listar speakers
curl http://localhost:8000/api/v1/speakers
```

## ðŸ›‘ Detener y Actualizar el Servicio

### Detener el servicio
```bash
# Detener contenedores (conserva datos)
docker-compose down

# Detener y eliminar volÃºmenes (âš ï¸ borra modelos descargados)
docker-compose down -v

# Detener y eliminar imÃ¡genes tambiÃ©n
docker-compose down --rmi all
```

### Actualizar el servicio
```bash
# Obtener Ãºltimos cambios del repositorio
git pull origin main

# Reconstruir imagen con cambios
docker-compose up -d --build

# O forzar reconstrucciÃ³n completa
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### Verificar estado
```bash
# Ver contenedores corriendo
docker ps

# Ver uso de recursos
docker stats qwen3-tts

# Ver logs con filtro
docker-compose logs -f qwen3-tts | grep ERROR
```

---

## ðŸ› SoluciÃ³n de Problemas

### Error: `docker: Error response from daemon: could not select device driver`
**SoluciÃ³n:** NVIDIA Docker Runtime no estÃ¡ instalado.
```bash
# Linux: Instalar nvidia-container-toolkit
sudo apt-get install nvidia-container-toolkit
sudo systemctl restart docker
```

### Error: `RuntimeError: CUDA out of memory`
**SoluciÃ³n:** La GPU no tiene suficiente VRAM.
```bash
# OpciÃ³n 1: Usar modelo mÃ¡s pequeÃ±o
echo "DEFAULT_MODEL_SIZE=0.6B" >> .env
docker-compose restart

# OpciÃ³n 2: Limitar longitud de audio
# Editar docker-compose.yml y aÃ±adir:
# environment:
#   - MAX_AUDIO_LENGTH_SECONDS=30
```

### Error: `Connection refused` al llamar a la API
**SoluciÃ³n:** El servicio aÃºn estÃ¡ iniciando o hay un error.
```bash
# Verificar estado
docker-compose ps

# Ver logs
docker-compose logs qwen3-tts

# Esperar a que descargue modelos (primera vez)
docker-compose logs -f qwen3-tts | grep "Application startup complete"
```

### Error: `ModuleNotFoundError: No module named 'qwen_tts'`
**SoluciÃ³n:** Reconstruir la imagen.
```bash
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### Modelos descargan muy lento
**SoluciÃ³n:** Configurar mirror de HuggingFace (China).
```bash
# Crear .env con mirror
cat >> .env << EOF
HF_ENDPOINT=https://hf-mirror.com
EOF
docker-compose restart
```

---

## ðŸ“Š Comandos Ãštiles

```bash
# Ver espacio usado por Docker
docker system df

# Limpiar cachÃ© de Docker
docker system prune -a

# Ejecutar comando dentro del contenedor
docker-compose exec qwen3-tts bash

# Ver archivos generados
ls -lah output/

# Copiar archivo desde contenedor
docker cp qwen3-tts:/app/output/audio.wav ./audio.wav

# Escuchar audio generado (Linux con paplay)
paplay output/audio.wav
```

---

## ðŸ”’ Seguridad

- El servicio expone el puerto 8000 solo en localhost por defecto
- Para acceso remoto, usar reverse proxy (nginx) con HTTPS
- No expongas el puerto 8000 directamente a internet sin autenticaciÃ³n
- Los archivos de audio en `output/` son accesibles por cualquiera con acceso al contenedor

---

## ðŸ“„ Licencia

Este proyecto utiliza Qwen3-TTS de Alibaba Cloud. Ver licencias originales:
- [Qwen3-TTS](https://huggingface.co/Qwen)

## ðŸ¤ Contribuciones

Issues y PRs son bienvenidos!

---

**Nota**: La primera ejecuciÃ³n descargarÃ¡ los modelos (~4-6GB), lo cual puede tardar varios minutos dependiendo de la conexiÃ³n.